{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tariquzzaman-faisal/VITD/blob/main/GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf89yMm_gbyH"
      },
      "source": [
        "# Mounting to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDgsHOADgeUD",
        "outputId": "195455c5-f5d5-4ea1-ef52-cae35a701c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FYGAXXtgVtT"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbFVYInVgwSY",
        "outputId": "6c8334a2-8e39-4bba-d7c8-32ed5598236c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWCQk7fNWJfU",
        "outputId": "5678eebc-fb1f-4ba5-a0bf-5b24d0a12ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.11.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "rr5qk44rXZG8"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GlobalMaxPool1D, Input, Flatten, MaxPooling1D, SpatialDropout1D, Activation\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from numpy import array\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import gensim\n",
        "from gensim import models\n",
        "from gensim.models import Word2Vec\n",
        "import fasttext.util\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m4VJe4ZgZ48"
      },
      "source": [
        "# Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ensf0hEagXMJ",
        "outputId": "80929c72-f2c8-4f5c-c26e-034b18ced8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "fasttext_model = fasttext.load_model(\"/content/drive/MyDrive/Research/Shared Task/Violence Inciting Text Detection (VITD) Bangla/notebooks/Tariq/fasttext/model_bn_300.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NJaX8jdjTOy"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rW3pzWRujWej"
      },
      "outputs": [],
      "source": [
        "train_dataset = pd.read_csv(\"/content/drive/MyDrive/Research/Shared Task/Violence Inciting Text Detection (VITD) Bangla/dataset/task datasets/original/train.csv\")\n",
        "val_dataset = pd.read_csv(\"/content/drive/MyDrive/Research/Shared Task/Violence Inciting Text Detection (VITD) Bangla/dataset/task datasets/original/dev.csv\")\n",
        "test_dataset = pd.read_csv(\"/content/drive/MyDrive/Research/Shared Task/Violence Inciting Text Detection (VITD) Bangla/dataset/task datasets/original/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUyj7RqZeM8X",
        "outputId": "59cfec2e-ea09-4263-9872-df17339744d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: (2700, 2)\n",
            "val: (1330, 2)\n",
            "test: (2016, 2)\n"
          ]
        }
      ],
      "source": [
        "print(f'train: {train_dataset.shape}\\nval: {val_dataset.shape}\\ntest: {test_dataset.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYLLzWUhe5eo"
      },
      "source": [
        "# Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "UYfQsmQ9fTX9"
      },
      "outputs": [],
      "source": [
        "# train_dataset['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "m8v7aCe3e7vQ"
      },
      "outputs": [],
      "source": [
        "# import math\n",
        "# # Find the maximum class frequency\n",
        "# max_class_frequency = train_dataset['label'].value_counts().max()\n",
        "\n",
        "# # Group the dataset by labels\n",
        "# grouped = train_dataset.groupby('label')\n",
        "\n",
        "# resampled_data = []\n",
        "# for label, group in grouped:\n",
        "#     if len(group) < max_class_frequency:\n",
        "#         oversampled_group = group.sample(max_class_frequency, replace=True, random_state=42)\n",
        "#         resampled_data.append(oversampled_group)\n",
        "#     else:\n",
        "#         resampled_data.append(group)\n",
        "\n",
        "# # Concatenate the resampled groups to create the balanced dataset\n",
        "# balanced_dataset = pd.concat(resampled_data)\n",
        "\n",
        "# # Shuffle the dataset to ensure randomness\n",
        "# balanced_dataset = balanced_dataset.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "UQ7n-ugOfDCZ"
      },
      "outputs": [],
      "source": [
        "# balanced_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Olrq-2mifHmS"
      },
      "outputs": [],
      "source": [
        "# balanced_dataset['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "9adUQHGkfYYX"
      },
      "outputs": [],
      "source": [
        "# train_dataset = balanced_dataset\n",
        "# train_dataset['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ljHyTfRMkn_R"
      },
      "outputs": [],
      "source": [
        "train_x = train_dataset['text']\n",
        "train_y = train_dataset['label']\n",
        "\n",
        "val_x = val_dataset['text']\n",
        "val_y = val_dataset['label']\n",
        "\n",
        "test_x = test_dataset['text']\n",
        "test_y = test_dataset['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giMvXGrki5KU"
      },
      "source": [
        "# Embedding Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "EXsyLO_IXBMM"
      },
      "outputs": [],
      "source": [
        "tokenizer=Tokenizer(oov_token = \"<OOV>\", split=' ') # Splitting text based on whitespace and adding \"Out of vocabulary\"\n",
        "tokenizer.fit_on_texts(train_x) # Using the tokenizer on out train dataset to tokenize the train dataset\n",
        "train_encoded=tokenizer.texts_to_sequences(train_x)\n",
        "# print(train_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "t8BEb_BT9_42"
      },
      "outputs": [],
      "source": [
        "train_padded= pad_sequences(train_encoded, padding='post', maxlen=256)\n",
        "# print(train_padded)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_padded.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u34pr8nkHX3G",
        "outputId": "40c17035-2976-4230-a249-30f59bb74f86"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "esuETwIM95zx"
      },
      "outputs": [],
      "source": [
        "# padding df_test\n",
        "test_encoded=tokenizer.texts_to_sequences(test_x)\n",
        "test_padded= pad_sequences(test_encoded, padding='post', maxlen=train_padded.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "g4qsNNT1t2-y"
      },
      "outputs": [],
      "source": [
        "# padding df_validation\n",
        "val_encoded=tokenizer.texts_to_sequences(val_x)\n",
        "val_padded= pad_sequences(val_encoded, padding='post', maxlen=train_padded.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "zZqz5UyxAMdp"
      },
      "outputs": [],
      "source": [
        "# function that takes word vector as input and returned an embedding layer\n",
        "def embedding_creation(EMBEDDING_DIM, word_vectors):\n",
        "  vocabulary_size=len(tokenizer.word_index)+1\n",
        "  word_index=tokenizer.word_index\n",
        "  embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
        "\n",
        "  for word, i in word_index.items():\n",
        "    try:\n",
        "      embedding_vector=word_vectors[word] # taking the word vector of all the words in the index\n",
        "      embedding_matrix[i]=embedding_vector # inserting the vector of the word to the embeddings matrix,  index wise\n",
        "    except KeyError:\n",
        "      embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
        "      \"\"\"\n",
        "      The strategy of generating random vectors for missing words (KeyError)\n",
        "      in the embedding matrix is useful because it provides a way to\n",
        "      include out-of-vocabulary words in the representation,\n",
        "        prevents loss of information, helps with stable training, and\n",
        "        ensures a complete embedding matrix for neural network models.\n",
        "      \"\"\"\n",
        "  embedding_layer=Embedding(vocabulary_size, EMBEDDING_DIM, weights=[embedding_matrix], trainable=False)\n",
        "\n",
        "  return embedding_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "aQWBEGLNXGGS"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 300\n",
        "wv = fasttext_model\n",
        "IFT = embedding_creation(EMBEDDING_DIM, wv)\n",
        "# gets the embedding layer from the word vectors using EMBEDDING_DIM as dim size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "I50cEoD6llk1"
      },
      "outputs": [],
      "source": [
        "max_length = train_padded.shape[1]\n",
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "# creating a randomly initialized embedding layer (RE)\n",
        "RE = Embedding(vocabulary_size, EMBEDDING_DIM,input_length = max_length, trainable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8I5NkrOmKWA"
      },
      "source": [
        "# Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "v3unBndBmL5x"
      },
      "outputs": [],
      "source": [
        "earlystop_callback = EarlyStopping(\n",
        "    monitor =\"val_loss\",\n",
        "    min_delta=0,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    mode=\"min\",\n",
        "    restore_best_weights=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Fg7gJW-pmYfy",
        "outputId": "1bf10032-0747-4fc6-b6cb-2be5e0071ed6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIFT = embedding_creation(EMBEDDING_DIM, wv)\\n# IFT has the embedding layer from the word vectors using EMBEDDING_DIM as dim size\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "emb_X_name_collection = [ [IFT, 'IFT']]\n",
        "\"\"\"\n",
        "IFT = embedding_creation(EMBEDDING_DIM, wv)\n",
        "# IFT has the embedding layer from the word vectors using EMBEDDING_DIM as dim size\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHJOgEjQmV0g"
      },
      "source": [
        "# Model Configuration Orignal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjgoW5ijbNdc",
        "outputId": "505af1b1-4724-4179-bb75-76c77868881b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "BCgZ0F0fcsT1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Layer, Embedding, Bidirectional, LSTM, GlobalMaxPool1D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow.keras.backend as K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n17WQX4nsZd-"
      },
      "source": [
        "# Attention without maxpool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "fBpIi7p1sYaQ"
      },
      "outputs": [],
      "source": [
        "# # Define the custom attention mechanism as a subclass of Layer\n",
        "# class AttentionLayer(Layer):\n",
        "#     def __init__(self, **kwargs):\n",
        "#         super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "#     def build(self, input_shape):\n",
        "#         self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
        "#                                  initializer='random_normal', trainable=True)\n",
        "#         super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "#     def call(self, x):\n",
        "#         e = K.tanh(K.dot(x, self.W))  # Calculate alignment scores\n",
        "#         alpha = K.softmax(e, axis=1)   # Compute attention weights\n",
        "#         weighted_sum = x * alpha       # Apply attention to input\n",
        "#         return K.sum(weighted_sum, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOodZ8uZsVsD"
      },
      "source": [
        "# Attention for maxpool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "nWCGrAlIOslc"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import GRU, Dense, GlobalMaxPooling1D\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # Define the Attention Layer\n",
        "# class AttentionLayer(tf.keras.layers.Layer):\n",
        "#     def __init__(self, **kwargs):\n",
        "#         super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "#     def build(self, input_shape):\n",
        "#         self.W_q = self.add_weight(name='W_q',\n",
        "#                                   shape=(input_shape[-1], input_shape[-1]),\n",
        "#                                   initializer='uniform',\n",
        "#                                   trainable=True)\n",
        "#         super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "#     def call(self, x):\n",
        "#         q = tf.tanh(tf.matmul(x, self.W_q))\n",
        "#         a = tf.nn.softmax(q, axis=-1)\n",
        "#         x = x * a\n",
        "#         return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVQo1TdIQvwh"
      },
      "source": [
        "# With attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "5w7lQ-fUPTB4"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import GRU, Dense\n",
        "\n",
        "# num_classes = 3\n",
        "\n",
        "# # Loop through each embedding layer and create models with attention\n",
        "# for emb_X_name in emb_X_name_collection:\n",
        "#     model = Sequential([\n",
        "#         emb_X_name[0],\n",
        "#         GRU(100, dropout=0.4, return_sequences=True),  # Use GRU instead of LSTM\n",
        "#         AttentionLayer(),  # Use the custom attention layer\n",
        "#         Dense(64, activation='elu'),\n",
        "#         Dense(32, activation='relu'),\n",
        "#         Dense(16, activation='relu'),\n",
        "#         Dense(num_classes, activation='softmax'),  # Use softmax for multi-class classification\n",
        "#     ],\n",
        "#     name=\"Sentiment_Model\")\n",
        "\n",
        "#     model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsuZnIJ6Qx-E"
      },
      "source": [
        "# Without attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "CYE1I5WMnrVF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "num_classes = 3\n",
        "learning_rate = 0.001  # Adjust the learning rate as needed\n",
        "\n",
        "for emb_X_name in emb_X_name_collection:\n",
        "    model = Sequential([\n",
        "        emb_X_name[0],\n",
        "        GRU(150, dropout=0.3, return_sequences=True),\n",
        "        GlobalMaxPool1D(),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax'),  # Use softmax for multi-class classification\n",
        "    ],\n",
        "    name=\"Sentiment_Model\")\n",
        "    optimizer = Adam(learning_rate=learning_rate)  # Set the learning rate for the optimizer\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Use sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1FWujr5g9V0"
      },
      "source": [
        "# Attention + Maxpool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "HScp87IKhGMv"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import GRU, Dense\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# num_classes = 3\n",
        "\n",
        "# # Loop through each embedding layer and create models with attention\n",
        "# for emb_X_name in emb_X_name_collection:\n",
        "#     model = Sequential([\n",
        "#         emb_X_name[0],\n",
        "#         GRU(100, dropout=0.4, return_sequences=True),  # Use GRU instead of LSTM\n",
        "#         AttentionLayer(),  # Use the custom attention layer\n",
        "#         GlobalMaxPooling1D(),\n",
        "#         Dense(64, activation='elu'),\n",
        "#         Dense(32, activation='relu'),\n",
        "#         Dense(16, activation='relu'),\n",
        "#         Dense(num_classes, activation='softmax'),  # Use softmax for multi-class classification\n",
        "#     ],\n",
        "#     name=\"Sentiment_Model\")\n",
        "#     optimizer = Adam(learning_rate=2e-5)  # You can adjust the learning rate as needed\n",
        "#     model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GrlXAWIIsot",
        "outputId": "ce6accb4-774a-4abf-bf3a-58da279f66c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Sentiment_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 300)         3052200   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, None, 150)         203400    \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Gl  (None, 150)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                4832      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3260531 (12.44 MB)\n",
            "Trainable params: 208331 (813.79 KB)\n",
            "Non-trainable params: 3052200 (11.64 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz843Nf_mlVo"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs0qseUXmmgT",
        "outputId": "14570268-215d-4d65-d791-d6195494584d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "85/85 [==============================] - 43s 485ms/step - loss: 0.8908 - accuracy: 0.5993 - val_loss: 0.7457 - val_accuracy: 0.6850\n",
            "Epoch 2/100\n",
            "85/85 [==============================] - 29s 341ms/step - loss: 0.6778 - accuracy: 0.7193 - val_loss: 0.6363 - val_accuracy: 0.7368\n",
            "Epoch 3/100\n",
            "85/85 [==============================] - 30s 357ms/step - loss: 0.5805 - accuracy: 0.7615 - val_loss: 0.6282 - val_accuracy: 0.7323\n",
            "Epoch 4/100\n",
            "85/85 [==============================] - 29s 339ms/step - loss: 0.5296 - accuracy: 0.7770 - val_loss: 0.6304 - val_accuracy: 0.7383\n",
            "Epoch 5/100\n",
            "85/85 [==============================] - 31s 363ms/step - loss: 0.4786 - accuracy: 0.8178 - val_loss: 0.5961 - val_accuracy: 0.7436\n",
            "Epoch 6/100\n",
            "85/85 [==============================] - 30s 357ms/step - loss: 0.4450 - accuracy: 0.8278 - val_loss: 0.6054 - val_accuracy: 0.7541\n",
            "Epoch 7/100\n",
            "85/85 [==============================] - 30s 351ms/step - loss: 0.3759 - accuracy: 0.8607 - val_loss: 0.6525 - val_accuracy: 0.7331\n",
            "Epoch 8/100\n",
            "85/85 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8841Restoring model weights from the end of the best epoch: 5.\n",
            "85/85 [==============================] - 29s 339ms/step - loss: 0.3298 - accuracy: 0.8841 - val_loss: 0.6343 - val_accuracy: 0.7496\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_padded, train_y, epochs=100, batch_size=32, validation_data=(val_padded, val_y), callbacks=[earlystop_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoHKGgEupl-2",
        "outputId": "320f32ba-a6d5-4059-bbff-cc30d7835718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 9s 136ms/step\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict(test_padded)\n",
        "\n",
        "p = []\n",
        "for i in range(len(prediction)):\n",
        "    a = []\n",
        "    for j in range(3):\n",
        "        a.append(round(prediction[i][j]))\n",
        "    p.append(a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC4iGktnquoj",
        "outputId": "609465a7-a3ba-4f26-ad0a-3e6f37036388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4404862 , 0.4968601 , 0.06265371],\n",
              "       [0.6095443 , 0.15504445, 0.23541118],\n",
              "       [0.9849346 , 0.01266591, 0.00239954],\n",
              "       ...,\n",
              "       [0.03784822, 0.02404939, 0.9381024 ],\n",
              "       [0.03460599, 0.06336546, 0.9020286 ],\n",
              "       [0.93616647, 0.04867815, 0.01515536]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "AaoY93Hwr-Bo"
      },
      "outputs": [],
      "source": [
        "# Determine the maximum column index for each row\n",
        "max_indices = np.argmax(p, axis=1)\n",
        "\n",
        "# Create a DataFrame with the max_indices\n",
        "pred_labels = pd.DataFrame({'Value': max_indices})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "87NCc7M8sDFi",
        "outputId": "430bd373-961e-429f-de29-3803765e92f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Value\n",
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         1\n",
              "...     ...\n",
              "2011      0\n",
              "2012      1\n",
              "2013      2\n",
              "2014      2\n",
              "2015      0\n",
              "\n",
              "[2016 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-291dd23a-b2ba-4450-9cef-c8328fa0aa73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2016 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-291dd23a-b2ba-4450-9cef-c8328fa0aa73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-291dd23a-b2ba-4450-9cef-c8328fa0aa73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-291dd23a-b2ba-4450-9cef-c8328fa0aa73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8a84d89-ea89-4afa-9a6d-df0b02dddd38\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8a84d89-ea89-4afa-9a6d-df0b02dddd38')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8a84d89-ea89-4afa-9a6d-df0b02dddd38 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "pred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "dQPjc_zFqVcl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['neutral', 'passive', 'active']\n",
        "r = classification_report(test_y, pred_labels, output_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euOPNsvGr1KN",
        "outputId": "52dcfb82-5789-428d-dd37-3880d8fd3c7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.7399103139013453,\n",
              "  'recall': 0.9032846715328468,\n",
              "  'f1-score': 0.8134757600657354,\n",
              "  'support': 1096},\n",
              " '1': {'precision': 0.8211206896551724,\n",
              "  'recall': 0.5299026425591099,\n",
              "  'f1-score': 0.6441251056635672,\n",
              "  'support': 719},\n",
              " '2': {'precision': 0.602803738317757,\n",
              "  'recall': 0.6417910447761194,\n",
              "  'f1-score': 0.6216867469879518,\n",
              "  'support': 201},\n",
              " 'accuracy': 0.7440476190476191,\n",
              " 'macro avg': {'precision': 0.7212782472914249,\n",
              "  'recall': 0.6916594529560253,\n",
              "  'f1-score': 0.6930958709057515,\n",
              "  'support': 2016},\n",
              " 'weighted avg': {'precision': 0.7552038845733198,\n",
              "  'recall': 0.7440476190476191,\n",
              "  'f1-score': 0.7339555655499648,\n",
              "  'support': 2016}}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHn57ZNOsQ22",
        "outputId": "6acccba3-fabe-4c4d-ee37-4a9137d0a061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score      support\n",
            "0              0.739910  0.903285  0.813476  1096.000000\n",
            "1              0.821121  0.529903  0.644125   719.000000\n",
            "2              0.602804  0.641791  0.621687   201.000000\n",
            "accuracy       0.744048  0.744048  0.744048     0.744048\n",
            "macro avg      0.721278  0.691659  0.693096  2016.000000\n",
            "weighted avg   0.755204  0.744048  0.733956  2016.000000\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(r)\n",
        "\n",
        "# Transpose the DataFrame\n",
        "df = df.transpose()\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBm2Pr-RtdbY",
        "outputId": "9cdca845-993c-4941-89d7-ba04624c0d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# model.save(\"/content/drive/MyDrive/Research/Shared Task/Violence Inciting Text Detection (VITD) Bangla/notebooks/Tariq/final/GRU.h5\")  # Save the model in an h5 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "mJNvgltfsnl1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}